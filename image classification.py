# -*- coding: utf-8 -*-
"""Assignment_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hWvxDskZBTZ-k9dp1k5FpyAmAFxKiKdg
"""

import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
import torch
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

batch_size = 32
learning_rate = 0.001
momentum = 0.9


train_set = torchvision.datasets.CIFAR10(
    root='./data', train=True, transform=transforms.ToTensor(), download=True)

test_set = torchvision.datasets.CIFAR10(
    root='./data', train=False,transform=transforms.ToTensor())

# Dataloaders
test_loader = torch.utils.data.DataLoader(
    dataset=test_set, batch_size=batch_size, shuffle=False)

print(len(train_set))
print(len(test_set))

plt.imshow(np.moveaxis(np.squeeze(train_set[200][0].numpy()),0,-1)) # the color channel needs to be the last dimension

plt.imshow(np.moveaxis(np.squeeze(train_set[12][0].numpy()),0,-1))

plt.imshow(np.moveaxis(np.squeeze(train_set[4][0].numpy()),0,-1))

plt.imshow(np.moveaxis(np.squeeze(train_set[5000][0].numpy()),0,-1))

plt.imshow(np.moveaxis(np.squeeze(train_set[1][0].numpy()),0,-1))

#mean_tot = [0.4914, 0.4822, 0.4465]
#std_tot = [0.247, 0.243, 0.261]

# Write and execute code to verify that the mean/std are the same as the hint given in the assignment(correct).
import torch
import numpy
import torchvision.datasets as datasets
from torchvision import transforms

cifar_total_set = train_set+test_set
cifar_total_set1 = [item[0] for item in cifar_total_set] # item[0] and item[1] are image and its label
cifar_total_set1 = torch.stack(cifar_total_set1, dim=0)

mean_r = (cifar_total_set1[:,0,:,:]).mean()
mean_g = (cifar_total_set1[:,1,:,:]).mean()
mean_b = (cifar_total_set1[:,2,:,:]).mean()

std_r = (cifar_total_set1[:,0,:,:]).std()
std_g = (cifar_total_set1[:,1,:,:]).std()
std_b = (cifar_total_set1[:,2,:,:]).std()

mean_total = [mean_r,mean_g,mean_b]
std_total = [std_r,std_g,std_b]

print(std_r,std_g,std_b)
print(mean_r,mean_g,mean_b)

#normalize the data
transformation = torchvision.transforms.Compose([
    torchvision.transforms.ToTensor(),
    torchvision.transforms.Normalize(
        mean = mean_total,
        std = std_total,
    ),
])

train_set = torchvision.datasets.CIFAR10(
    root='./data', train=True, transform=transformation, download=True)

test_set = torchvision.datasets.CIFAR10(
    root='./data', train=False,transform=transformation)

test_loader = torch.utils.data.DataLoader(
    dataset=test_set, batch_size=batch_size, shuffle=False)

# Check that mean and std are 0 and 1 respectively. 
cifar_total_set = train_set+test_set
cifar_total_set1 = [item[0] for item in cifar_total_set] # item[0] and item[1] are image and its label
cifar_total_set1 = torch.stack(cifar_total_set1, dim=0)

mean_r = (cifar_total_set1[:,0,:,:]).mean()
mean_g = (cifar_total_set1[:,1,:,:]).mean()
mean_b = (cifar_total_set1[:,2,:,:]).mean()

std_r = (cifar_total_set1[:,0,:,:]).std()
std_g = (cifar_total_set1[:,1,:,:]).std()
std_b = (cifar_total_set1[:,2,:,:]).std()

mean_total = [mean_r,mean_g,mean_b]
std_total = [std_r,std_g,std_b]

print(std_r,std_g,std_b)
print(mean_r,mean_g,mean_b)

plt.imshow(np.moveaxis(np.squeeze(train_set[4][0].numpy()),0,-1))

idx = np.arange(len(train_set))

# Use last 5000 images for validation
val_indices = idx[50000-1000:]
train_indices= idx[:-1000]

print(len(val_indices))
print(len(train_indices))

train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)
valid_sampler = torch.utils.data.SubsetRandomSampler(val_indices)

train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,
                                          sampler=train_sampler, num_workers=2)

valid_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,
                                          sampler=valid_sampler, num_workers=2)


prob_loader = torch.utils.data.DataLoader(train_set, batch_size=1,                # this is going to be used for the random selection of the validation images for question 1.3.6
                                          sampler=valid_sampler, num_workers=2)

# Implement the following convolutional neural network using rectified linear activation functions (ReLUs)
class ConvolutionalModel(nn.Module):
      def __init__(self):
        super(ConvolutionalModel, self).__init__()
        self.conv_layer_1 = nn.Conv2d(3, 32, 3) #nn.conv2d takes as first argument input channels, output channels and size of kernel.
        self.conv_layer_2 = nn.Conv2d(32, 32, 3) #input of layer 2 is output of previous layer that is why 32 input channels in th second layer
        self.Max_Pool_1 = nn.MaxPool2d(2)
        self.conv_layer_3 = nn.Conv2d(32,64,3)
        self.conv_layer_4 = nn.Conv2d(64, 64, 3)
        self.Max_Pool_2 = nn.MaxPool2d(2)
        self.flaten  = nn.Flatten() # flatten the data before putting on the fully connected layer
        self.fc1 = nn.Linear(64 * 5 * 5 , 512)
        self.fc2 = nn.Linear(512 , 10) # 10 because we have 10 classes classified on the beggining of the assignment
        self.activation = nn.ReLU(inplace=True)

      def forward(self, x):
        out = self.activation(self.conv_layer_1(x))
        #print(out.shape)
        out = self.activation(self.conv_layer_2(out))
        #print(out.shape)
        out = self.activation(self.Max_Pool_1(out))
        #print(out.shape)
        out = self.activation(self.conv_layer_3(out))
        #print(out.shape)
        out = self.activation(self.conv_layer_4(out))
        #print(out.shape)
        out = self.activation(self.Max_Pool_2(out))
        #print(out.shape)
        out = self.flaten(out)
        #print(out.shape)
        out = self.activation(self.fc1(out))
        #print(out.shape)
        out = self.fc2(out) # we do not put an activation function on the last output layer
        #print(out.shape)

        return out

DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model = ConvolutionalModel()
model = model.to(device) # put all model params on GPU.

# Create loss and optimizer
learning_rate = 0.001
momentum = 0.9
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)

# for training:
batch_size = 32
num_epochs = 20

training_accurracy = []
training_loss = []
validation_accurracy = []
validation_loss = []
best_epoch = 0  #variable which is going to store the best epoch where the validation accuracy is going to be highest
best_validation_accurracy = -1000 # initialize the best accurracy with a negative number to use it down for comparison

for epoch in range(1, num_epochs):
    running_loss = 0.0
    validation_running_loss = 0.0
    running_total = 0
    running_correct = 0
    run_step = 1
    for i, (images, labels) in enumerate(train_loader):
        model.train()  # put the model to train mode
        # shape of input images is (B, 1, 28, 28).
        #images = images.view(-1, 22*22)  # reshape to (B, 784).
        images = images.to(device)
        labels = labels.to(device)
        #print(images.shape)  # shape (B).
        outputs = model(images) 
        #print(outputs.shape) # shape (B, 10).
        loss = loss_fn(outputs, labels)
        optimizer.zero_grad()  # reset gradients.
        loss.backward()  # compute gradients.
        optimizer.step()  # update parameters.

        running_loss += loss.item()
        running_total += labels.size(0)

        with torch.no_grad():
            _, predicted = outputs.max(1)
        running_correct += (predicted == labels).sum().item()
        run_step += 1
        if i % 200 == 0:
            # check accuracy.
            print(f'epoch: {epoch}, steps: {i}, '
                  f'train_loss: {running_loss / run_step :.3f}, '
                  f'running_acc: {100 * running_correct / running_total:.1f} %')
            
            train_accu = (100 * running_correct / running_total)
            train_loss = (running_loss / run_step)
            training_accurracy.append([i+(epoch*len(train_loader)), train_accu])
            training_loss.append([i+(epoch*len(train_loader)), train_loss])
            running_loss = 0.0
            running_total = 0
            running_correct = 0
            run_step = 1

    # validation
    correct = 0
    total = 0
    validation_step = 0
    model.eval()
    with torch.no_grad():
        for data in valid_loader:
            validation_step = validation_step + 1
            images, labels = data
            images, labels = images.to(device), labels.to(device)
            #images = images.view(-1, 32*32)
            outputs = model(images)
            _, predicted = outputs.max(1)
            total += labels.size(0)
            val_loss = loss_fn(outputs, labels)
            validation_running_loss = validation_running_loss + val_loss.item()
            correct += (predicted == labels).sum().item()
            val_acc = 100 * correct / total

    # NB: : .1f specifies that you want 1 floating point
    # TODO: you need to add code to keep track of the best so-far validation
    # accuracy, and the corresponding model parameters.
    if (val_acc > best_validation_accurracy):
      best_validation_accurracy = val_acc
      best_epoch = epoch
      #torch.squeeze(best_validation_accurracy)
    print(f'Validation accuracy: {100 * correct / total: .1f} %')

    val_loss = (validation_running_loss / validation_step)
    step = (epoch + 1) * len(train_loader)
    validation_accurracy.append([step, val_acc])
    validation_loss.append([step, val_loss])

print('Finished Training')
print(f"On the best epoch:{best_epoch}, we have reached the best validation accurracy:{best_validation_accurracy}")

# Plot the evolution of the loss for the training set.

import matplotlib.pyplot as plt
import numpy as np 

plt.scatter(np.array(training_loss)[:, 0][:, None], np.array(training_loss)[:, 1][:, None], alpha = 0.3, marker = 'o', color = 'blue') 
plt.scatter(np.array(validation_loss)[:, 0][:, None], np.array(validation_loss)[:, 1][:, None], alpha = 0.5, marker = 'o', color = 'purple') 
plt.title('Traning Loss (in blue) and validation loss (in purple)')
plt.xlabel('step + epoch*len(step)')
plt.ylabel('Loss')
plt.show()

# Plot the accurracy of the loss for the training set.

import matplotlib.pyplot as plt
import numpy as np 

plt.scatter(np.array(training_accurracy)[:, 0][:, None], np.array(training_accurracy)[:, 1][:, None], alpha = 0.3, marker = 'o', color = 'red') 
plt.scatter(np.array(validation_accurracy)[:, 0][:, None], np.array(validation_accurracy)[:, 1][:, None], alpha = 0.5, marker = 'o', color = 'green') 
plt.title('Traning Accuracy (in red) and validtion accuracy(in green)')
plt.xlabel('step + epoch*len(step)')
plt.ylabel('Accurracy')
plt.show()

class ConvolutionalModelWithDropout(nn.Module):
      def __init__(self):
        super(ConvolutionalModelWithDropout, self).__init__()
        self.conv_layer_1 = nn.Conv2d(3, 32, 3) #nn.conv2d takes as first argument input channels, output channels and size of kernel.
        self.conv_layer_2 = nn.Conv2d(32, 32, 3) #input of layer 2 is output of previous layer that is why 32 input channels in th second layer
        self.Max_Pool_1 = nn.MaxPool2d(2)
        self.Dropout_1 = nn.Dropout(p = 0.5,inplace = False)
        self.conv_layer_3 = nn.Conv2d(32,64,3)
        self.conv_layer_4 = nn.Conv2d(64, 64, 3)
        self.Max_Pool_2 = nn.MaxPool2d(2)
        self.Dropout_2 = nn.Dropout(p = 0.5,inplace = False)
        self.flaten  = nn.Flatten() # flatten the data before putting on the fully connected layer
        self.fc1 = nn.Linear(64 * 5 * 5 , 512)
        self.fc2 = nn.Linear(512 , 10) # 10 b3cause we have 10 classes classified on the beggining of the assignment
        self.activation = nn.ReLU(inplace=True)

      def forward(self, x):
        out = self.activation(self.conv_layer_1(x))
        #print(out.shape)
        out = self.activation(self.conv_layer_2(out))
        #print(out.shape)
        out = self.Max_Pool_1(out)
        #print(out.shape)
        out = self.Dropout_1(out)
        #print(out.shape)
        out = self.activation(self.conv_layer_3(out))
        #print(out.shape)
        out = self.activation(self.conv_layer_4(out))
        #print(out.shape)
        out = self.Max_Pool_2(out)
        #print(out.shape)
        out = self.Dropout_2(out)
        #print(out.shape)
        out = self.flaten(out)
        #print(out.shape)
        out = self.activation(self.fc1(out))
        #print(out.shape)
        out = self.fc2(out)
        #print(out.shape)

        return out

DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model_dropout = ConvolutionalModelWithDropout()
model_dropout = model_dropout.to(device) # put all model params on GPU.

# Create loss and optimizer
learning_rate = 0.001
momentum = 0.9
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model_dropout.parameters(), lr=learning_rate, momentum=momentum)

# for training:
batch_size = 32
num_epochs = 40

dropout_training_accurracy = []
dropout_training_loss = []
dropout_validation_accurracy = []
dropout_validation_loss = []
dropout_best_epoch = 0
dropout_best_validation_accurracy = -1000 # initialize the best accurracy with a negative number to use it down for comparison

for epoch in range(1, num_epochs):
    running_loss = 0.0
    validation_running_loss = 0.0
    running_total = 0
    running_correct = 0
    run_step = 1
    for i, (images, labels) in enumerate(train_loader):
        model_dropout.train()  # put the model to train mode
        # shape of input images is (B, 1, 28, 28).
        #images = images.view(-1, 22*22)  # reshape to (B, 784).
        images = images.to(device)
        labels = labels.to(device)
        #print(images.shape)  # shape (B).
        outputs = model_dropout(images) 
        #print(outputs.shape) # shape (B, 10).
        loss = loss_fn(outputs, labels)
        optimizer.zero_grad()  # reset gradients.
        loss.backward()  # compute gradients.
        optimizer.step()  # update parameters.

        running_loss += loss.item()
        running_total += labels.size(0)

        with torch.no_grad():
            _, predicted = outputs.max(1)
        running_correct += (predicted == labels).sum().item()
        run_step += 1
        if i % 200 == 0:
            # check accuracy.
            print(f'epoch: {epoch}, steps: {i}, '
                  f'train_loss: {running_loss / run_step :.3f}, '
                  f'running_acc: {100 * running_correct / running_total:.1f} %')
            
            train_accu = (100 * running_correct / running_total)
            train_loss = (running_loss / run_step)
            dropout_training_accurracy.append([i+(epoch*len(train_loader)), train_accu])
            dropout_training_loss.append([i+(epoch*len(train_loader)), train_loss])
            running_loss = 0.0
            running_total = 0
            running_correct = 0
            run_step = 1

    # validation
    correct = 0
    total = 0
    validation_step = 0
    model_dropout.eval()
    with torch.no_grad():
        for data in valid_loader:
            validation_step = validation_step + 1
            images, labels = data
            images, labels = images.to(device), labels.to(device)
            #images = images.view(-1, 32*32)
            outputs = model_dropout(images)
            _, predicted = outputs.max(1)
            total += labels.size(0)
            val_loss = loss_fn(outputs, labels)
            validation_running_loss = validation_running_loss + val_loss.item()
            correct += (predicted == labels).sum().item()
            val_acc = 100 * correct / total

    # NB: : .1f specifies that you want 1 floating point
    # TODO: you need to add code to keep track of the best so-far validation
    # accuracy, and the corresponding model parameters.
    if (val_acc > dropout_best_validation_accurracy):
      dropout_best_validation_accurracy = val_acc
      dropout_best_epoch = epoch
      #torch.squeeze(best_validation_accurracy)
    print(f'Validation accuracy: {100 * correct / total: .1f} %')

    val_loss = (validation_running_loss / validation_step)
    step = (epoch + 1) * len(train_loader)
    dropout_validation_accurracy.append([step, val_acc])
    dropout_validation_loss.append([step, val_loss])

print('Finished Training')
print(f"On the best epoch:{dropout_best_epoch}, we have reached the best validation accurracy:{dropout_best_validation_accurracy}")

import matplotlib.pyplot as plt
import numpy as np 

plt.scatter(np.array(dropout_training_loss)[:, 0][:, None], np.array(dropout_training_loss)[:, 1][:, None], alpha = 0.3, marker = 'o', color = 'blue') 
plt.scatter(np.array(dropout_validation_loss)[:, 0][:, None], np.array(dropout_validation_loss)[:, 1][:, None], alpha = 0.5, marker = 'o', color = 'purple') 
plt.title('Traning Loss (in blue) and validation loss (in purple)')
plt.xlabel('step + epoch*len(step)')
plt.ylabel('Loss')
plt.show()

import matplotlib.pyplot as plt
import numpy as np 

plt.scatter(np.array(dropout_training_accurracy)[:, 0][:, None], np.array(dropout_training_accurracy)[:, 1][:, None], alpha = 0.3, marker = 'o', color = 'red') 
plt.scatter(np.array(dropout_validation_accurracy)[:, 0][:, None], np.array(dropout_validation_accurracy)[:, 1][:, None], alpha = 0.5, marker = 'o', color = 'green') 
plt.title('Traning Accuracy (in red) and validtion accuracy(in green)')
plt.xlabel('step + epoch*len(step)')
plt.ylabel('Accurracy')
plt.show()

test_loader = torch.utils.data.DataLoader(test_set)
correct = 0
total = 0

model_dropout.eval()
testing_step = 0
testing_loss = 0
with torch.no_grad():
    for data in test_loader:
        testing_step += 1
        images, labels = data
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = outputs.max(1)
        total += labels.size(0)
        
        loss_t = loss_fn(outputs, labels)
        testing_loss += loss_t.item()

        correct += (predicted == labels).sum().item()
        val_acc = 100 * correct / total

print(f'Test accuracy: {100 * correct / total} %')

model_dropout.eval()

#print(prob_loader)
with torch.no_grad():
    images, classes = next(iter(prob_loader)) 
    plt.imshow(np.moveaxis(np.squeeze(images[0].numpy()),0,-1))
    images, labels = images.to(device), classes.to(device)
    outputs = model_dropout(images)
    soft = torch.nn.Softmax(dim=1)
    outputs = soft(outputs)
print(f'Probability distribution: {(outputs)} %')
print(f'Label: {labels} %')

class ConvolutionalModelBonus(nn.Module):
      def __init__(self):
        super(ConvolutionalModelBonus, self).__init__()
        self.conv_layer_1 = nn.Conv2d(3, 32, 3) #nn.conv2d takes as first argument input channels, output channels and size of kernel.
        self.conv_layer_2 = nn.Conv2d(32, 32, 3) #input of layer 2 is output of previous layer that is why 32 input channels in th second layer
        self.Max_Pool_1 = nn.MaxPool2d(2)
        self.Dropout_1 = nn.Dropout(p = 0.5,inplace = False)
        self.conv_layer_3 = nn.Conv2d(32, 64, 3)
        self.conv_layer_4 = nn.Conv2d(64, 64, 3, padding = 1)
        self.conv_layer_5 = nn.Conv2d(64, 64, 3)
        self.Max_Pool_2 = nn.MaxPool2d(2)
        self.Dropout_2 = nn.Dropout(p = 0.5,inplace = False)
        self.flaten  = nn.Flatten() # flatten the data before putting on the fully connected layer
        self.fc1 = nn.Linear(64 * 5 * 5 , 512)
        self.fc2 = nn.Linear(512 , 10) # 10 b3cause we have 10 classes classified on the beggining of the assignment
        self.Dropout_3 = nn.Dropout(p = 0.5, inplace = False)
        self.activation = nn.LeakyReLU(negative_slope=0.01, inplace=False)

      def forward(self, x):
        out = self.activation(self.conv_layer_1(x))
        #print(out.shape)
        out = self.activation(self.conv_layer_2(out))
        #print(out.shape)
        out = self.Max_Pool_1(out)
        #print(out.shape)
        out = self.Dropout_1(out)
        #print(out.shape)
        out = self.activation(self.conv_layer_3(out))
        #print(out.shape)
        out = self.activation(self.conv_layer_4(out))
        #print(out.shape)
        out = self.activation(self.conv_layer_5(out))
        #print(out.shape)
        out = self.Max_Pool_2(out)
        #print(out.shape)
        out = self.Dropout_2(out)
        #print(out.shape)
        out = self.flaten(out)
        #print(out.shape)
        out = self.activation(self.fc1(out))
        #print(out.shape)
        out = self.Dropout_3(out)
        #print(out.shape)
        out = self.fc2(out)
        #print(out.shape)

        return out

DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model_bonus = ConvolutionalModelBonus()
model_bonus = model_bonus.to(device) # put all model params on GPU.

# Create loss and optimizer
learning_rate = 0.001
momentum = 0.9
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model_bonus.parameters(), lr=learning_rate, momentum=momentum)

# for training:
batch_size = 32
num_epochs = 80

bonus_training_accurracy = []
bonus_training_loss = []
bonus_validation_accurracy = []
bonus_validation_loss = []
bonus_best_epoch = 0
bonus_best_validation_accurracy = -1000 # initialize the best accurracy with a negative number to use it down for comparison

for epoch in range(1, num_epochs):
    running_loss = 0.0
    validation_running_loss = 0.0
    running_total = 0
    running_correct = 0
    run_step = 1
    for i, (images, labels) in enumerate(train_loader):
        model_bonus.train()  # put the model to train mode
        # shape of input images is (B, 1, 28, 28).
        #images = images.view(-1, 22*22)  # reshape to (B, 784).
        images = images.to(device)
        labels = labels.to(device)
        #print(images.shape)  # shape (B).
        outputs = model_bonus(images) 
        #print(outputs.shape) # shape (B, 10).
        loss = loss_fn(outputs, labels)
        optimizer.zero_grad()  # reset gradients.
        loss.backward()  # compute gradients.
        optimizer.step()  # update parameters.

        running_loss += loss.item()
        running_total += labels.size(0)

        with torch.no_grad():
            _, predicted = outputs.max(1)
        running_correct += (predicted == labels).sum().item()
        run_step += 1
        if i % 200 == 0:
            # check accuracy.
            print(f'epoch: {epoch}, steps: {i}, '
                  f'train_loss: {running_loss / run_step :.3f}, '
                  f'running_acc: {100 * running_correct / running_total:.1f} %')
            
            train_accu = (100 * running_correct / running_total)
            train_loss = (running_loss / run_step)
            bonus_training_accurracy.append([i+(epoch*len(train_loader)), train_accu])
            bonus_training_loss.append([i+(epoch*len(train_loader)), train_loss])
            running_loss = 0.0
            running_total = 0
            running_correct = 0
            run_step = 1

    # validation
    correct = 0
    total = 0
    validation_step = 0
    model_bonus.eval()
    with torch.no_grad():
        for data in valid_loader:
            validation_step = validation_step + 1
            images, labels = data
            images, labels = images.to(device), labels.to(device)
            #images = images.view(-1, 32*32)
            outputs = model_bonus(images)
            _, predicted = outputs.max(1)
            total += labels.size(0)
            val_loss = loss_fn(outputs, labels)
            validation_running_loss = validation_running_loss + val_loss.item()
            correct += (predicted == labels).sum().item()
            val_acc = 100 * correct / total

    # NB: : .1f specifies that you want 1 floating point
    # TODO: you need to add code to keep track of the best so-far validation
    # accuracy, and the corresponding model parameters.
    if (val_acc > bonus_best_validation_accurracy):
      bonus_best_validation_accurracy = val_acc
      bonus_best_epoch = epoch
      #torch.squeeze(best_validation_accurracy)
    print(f'Validation accuracy: {100 * correct / total: .1f} %')

    val_loss = (validation_running_loss / validation_step)
    step = (epoch + 1) * len(train_loader)
    bonus_validation_accurracy.append([step, val_acc])
    bonus_validation_loss.append([step, val_loss])

print('Finished Training')
print(f"On the best epoch:{bonus_best_epoch}, we have reached the best validation accurracy:{bonus_best_validation_accurracy}")

import matplotlib.pyplot as plt
import numpy as np 

plt.scatter(np.array(bonus_training_loss)[:, 0][:, None], np.array(bonus_training_loss)[:, 1][:, None], alpha = 0.3, marker = 'o', color = 'blue') 
plt.scatter(np.array(bonus_validation_loss)[:, 0][:, None], np.array(bonus_validation_loss)[:, 1][:, None], alpha = 0.5, marker = 'o', color = 'purple') 
plt.title('Traning Loss (in blue) and validation loss (in purple)')
plt.xlabel('step + epoch*len(step)')
plt.ylabel('Loss')
plt.show()

import matplotlib.pyplot as plt
import numpy as np 

plt.scatter(np.array(bonus_training_accurracy)[:, 0][:, None], np.array(bonus_training_accurracy)[:, 1][:, None], alpha = 0.3, marker = 'o', color = 'red') 
plt.scatter(np.array(bonus_validation_accurracy)[:, 0][:, None], np.array(bonus_validation_accurracy)[:, 1][:, None], alpha = 0.5, marker = 'o', color = 'green') 
plt.title('Traning Accuracy (in red) and validtion accuracy(in green)')
plt.xlabel('step + epoch*len(step)')
plt.ylabel('Accurracy')
plt.show()

test_loader = torch.utils.data.DataLoader(test_set)
correct = 0
total = 0

model_bonus.eval()
testing_step = 0
testing_loss = 0
with torch.no_grad():
    for data in test_loader:
        testing_step += 1
        images, labels = data
        images, labels = images.to(device), labels.to(device)
        outputs = model_bonus(images)
        _, predicted = outputs.max(1)
        total += labels.size(0)
        
        loss_t = loss_fn(outputs, labels)
        testing_loss += loss_t.item()

        correct += (predicted == labels).sum().item()
        val_acc = 100 * correct / total

print(f'Test set accuracy: {100 * correct / total} %')

correct = 0
total = 0

model_bonus.eval()
testing_step = 0
testing_loss = 0
print(prob_loader)
with torch.no_grad():
    images, classes = next(iter(prob_loader)) 
    plt.imshow(np.moveaxis(np.squeeze(images[0].numpy()),0,-1))
    images, labels = images.to(device), classes.to(device)
    outputs = model_bonus(images)
    soft = torch.nn.Softmax(dim=1)
    outputs = soft(outputs)
print(f'Probability distribution: {(outputs)} %')
print(f'Label: {labels} %')